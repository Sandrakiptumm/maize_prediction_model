{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from joblib import dump\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Year_sin</th>\n",
       "      <th>Year_cos</th>\n",
       "      <th>Wholesale_lag_7</th>\n",
       "      <th>Retail_lag_7</th>\n",
       "      <th>Wholesale_rolling_mean_7d</th>\n",
       "      <th>Retail_rolling_mean_7d</th>\n",
       "      <th>Wholesale_rolling_std_7d</th>\n",
       "      <th>Retail_rolling_std_7d</th>\n",
       "      <th>Wholesale</th>\n",
       "      <th>Retail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-24</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.78</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.115639</td>\n",
       "      <td>0.142735</td>\n",
       "      <td>0.016814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041655</td>\n",
       "      <td>0.062485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-24</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.78</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.104055</td>\n",
       "      <td>0.142735</td>\n",
       "      <td>0.016814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033315</td>\n",
       "      <td>0.062485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.78</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.112542</td>\n",
       "      <td>0.148688</td>\n",
       "      <td>0.019208</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.046650</td>\n",
       "      <td>0.070298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.78</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.116785</td>\n",
       "      <td>0.140056</td>\n",
       "      <td>0.017940</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>0.046650</td>\n",
       "      <td>0.049985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.78</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.118406</td>\n",
       "      <td>0.137634</td>\n",
       "      <td>0.015975</td>\n",
       "      <td>0.014497</td>\n",
       "      <td>0.044985</td>\n",
       "      <td>0.056017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Year  Year_sin  Year_cos  Wholesale_lag_7  Retail_lag_7  \\\n",
       "0  2021-05-24  2021       0.0       1.0            27.78          40.0   \n",
       "1  2021-05-24  2021       0.0       1.0            27.78          40.0   \n",
       "2  2021-06-28  2021       0.0       1.0            27.78          40.0   \n",
       "3  2021-09-20  2021       0.0       1.0            27.78          40.0   \n",
       "4  2021-10-04  2021       0.0       1.0            27.78          40.0   \n",
       "\n",
       "   Wholesale_rolling_mean_7d  Retail_rolling_mean_7d  \\\n",
       "0                   0.115639                0.142735   \n",
       "1                   0.104055                0.142735   \n",
       "2                   0.112542                0.148688   \n",
       "3                   0.116785                0.140056   \n",
       "4                   0.118406                0.137634   \n",
       "\n",
       "   Wholesale_rolling_std_7d  Retail_rolling_std_7d  Wholesale    Retail  \n",
       "0                  0.016814               0.000000   0.041655  0.062485  \n",
       "1                  0.016814               0.000000   0.033315  0.062485  \n",
       "2                  0.019208               0.008545   0.046650  0.070298  \n",
       "3                  0.017940               0.015917   0.046650  0.049985  \n",
       "4                  0.015975               0.014497   0.044985  0.056017  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the data\n",
    "data = pd.read_csv(\"modeling_data_2.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15493 entries, 0 to 15492\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Date                       15493 non-null  object \n",
      " 1   Year                       15493 non-null  int64  \n",
      " 2   Year_sin                   15493 non-null  float64\n",
      " 3   Year_cos                   15493 non-null  float64\n",
      " 4   Wholesale_lag_7            15491 non-null  float64\n",
      " 5   Retail_lag_7               15491 non-null  float64\n",
      " 6   Wholesale_rolling_mean_7d  15493 non-null  float64\n",
      " 7   Retail_rolling_mean_7d     15493 non-null  float64\n",
      " 8   Wholesale_rolling_std_7d   15493 non-null  float64\n",
      " 9   Retail_rolling_std_7d      15493 non-null  float64\n",
      " 10  Wholesale                  15493 non-null  float64\n",
      " 11  Retail                     15493 non-null  float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"Date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                         0\n",
       "Year_sin                     0\n",
       "Year_cos                     0\n",
       "Wholesale_lag_7              2\n",
       "Retail_lag_7                 2\n",
       "Wholesale_rolling_mean_7d    0\n",
       "Retail_rolling_mean_7d       0\n",
       "Wholesale_rolling_std_7d     0\n",
       "Retail_rolling_std_7d        0\n",
       "Wholesale                    0\n",
       "Retail                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(columns=[\"Wholesale\", \"Retail\"])\n",
    "target1 = data[\"Wholesale\"]\n",
    "target2 = data[ \"Retail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (12394, 9)\n",
      "Testing set shape: (3099, 9)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_wholesale, X_test_wholesale, y_train_wholesale, y_test_wholesale = train_test_split(features, target1 , test_size=0.2, random_state=3000)\n",
    "\n",
    "print(f\"Training set shape: {X_train_wholesale.shape}\")\n",
    "print(f\"Testing set shape: {X_test_wholesale.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled X_train_wholesale shape: (12394, 10)\n",
      "Scaled y_train_wholesale shape: (12394, 1)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MinMaxScaler\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data (excluding 'Date' and 'Year' if necessary)\n",
    "columns_to_exclude = ['Year']\n",
    "\n",
    "# Select columns to scale\n",
    "X_train_to_scale = X_train_wholesale.drop(columns=columns_to_exclude)\n",
    "X_test_to_scale = X_test_wholesale.drop(columns=columns_to_exclude)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler_X.fit_transform(X_train_to_scale)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train_wholesale.values.reshape(-1, 1))\n",
    "\n",
    "# Transform the test data using the fitted scaler\n",
    "X_test_scaled = scaler_X.transform(X_test_to_scale)\n",
    "y_test_scaled = scaler_y.transform(y_test_wholesale.values.reshape(-1, 1))\n",
    "\n",
    "# Optionally, add back the excluded columns if you need them\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_to_scale.columns, index=X_train_wholesale.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_to_scale.columns, index=X_test_wholesale.index)\n",
    "\n",
    "# If you want to keep the Date and Year columns for reference (but not scaled), add them back to the scaled data\n",
    "X_train_scaled = pd.concat([X_train_wholesale[columns_to_exclude], X_train_scaled], axis=1)\n",
    "X_test_scaled = pd.concat([X_test_wholesale[columns_to_exclude], X_test_scaled], axis=1)\n",
    "\n",
    "# Now your data is ready for the model\n",
    "print(f\"Scaled X_train_wholesale shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled y_train_wholesale shape: {y_train_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Specify the columns to exclude\n",
    "# exclude_columns = ['Year', 'Wholesale', 'Retail']\n",
    "\n",
    "# # Separate the columns to be scaled and the excluded columns\n",
    "# columns_to_scale = .drop(columns=exclude_columns).columns\n",
    "# data_to_scale = data[columns_to_scale]\n",
    "\n",
    "# # Initialize MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # Apply MinMaxScaler to the columns that need scaling\n",
    "# data_scaled = pd.DataFrame(scaler.fit_transform(data_to_scale), columns=columns_to_scale)\n",
    "\n",
    "# # Recombine the scaled columns with the excluded columns (Date, Year)\n",
    "# data = pd.concat([data[exclude_columns].reset_index(drop=True), data_scaled], axis=1)\n",
    "\n",
    "# # Check the resulting scaled dataset\n",
    "# data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_lstm_wholesale: (12384, 10, 10)\n",
      "Shape of y_lstm_wholesale: (12384, 1)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "time_steps = 10  # Adjust this as needed\n",
    "\n",
    "# Assume X_train_wholesale and y_train_wholesale are already scaled using MinMaxScaler\n",
    "X_train_wholesale_scaled = np.array(X_train_scaled)  # Your scaled features\n",
    "y_train_wholesale_scaled = np.array(y_train_scaled)  # Your scaled target (reshaped)\n",
    "\n",
    "# Initialize lists to hold reshaped data\n",
    "X_lstm_wholesale = []\n",
    "y_lstm_wholesale = []\n",
    "\n",
    "# Loop over the scaled data to create sequences for LSTM\n",
    "for i in range(len(X_train_wholesale_scaled) - time_steps):\n",
    "    # For each step, grab the previous 'time_steps' of features\n",
    "    X_lstm_wholesale.append(X_train_wholesale_scaled[i:i + time_steps])\n",
    "    \n",
    "    # Grab the corresponding target value (Wholesale) at the next time step\n",
    "    y_lstm_wholesale.append(y_train_wholesale_scaled[i + time_steps])\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_lstm_wholesale = np.array(X_lstm_wholesale)\n",
    "y_lstm_wholesale = np.array(y_lstm_wholesale)\n",
    "\n",
    "# Check the shape of the reshaped data\n",
    "print(f\"Shape of X_lstm_wholesale: {X_lstm_wholesale.shape}\")  # Should be (samples, time_steps, features)\n",
    "print(f\"Shape of y_lstm_wholesale: {y_lstm_wholesale.shape}\")  # Should be (samples, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wholesale = np.array(X_train_wholesale).astype('float32')\n",
    "y_train_wholesale = np.array(y_train_wholesale).astype('float32')\n",
    "X_test_wholesale = np.array(X_test_wholesale).astype('float32')\n",
    "y_test_wholesale = np.array(y_test_wholesale).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12394, 9)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 111546 into shape (12394,10,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Reshape if necessary to ensure it's 3D\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X_train_wholesale\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Reshape to 3D: (samples, time_steps, features)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     X_train_wholesale \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_wholesale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_wholesale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Now define the model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 111546 into shape (12394,10,newaxis)"
     ]
    }
   ],
   "source": [
    "# Check the shape of X_train_wholesale\n",
    "print(X_train_wholesale.shape)  # This should be (samples, time_steps, features)\n",
    "\n",
    "# Reshape if necessary to ensure it's 3D\n",
    "if len(X_train_wholesale.shape) == 2:\n",
    "    # Reshape to 3D: (samples, time_steps, features)\n",
    "    X_train_wholesale = .reshape((X_lstm_wholesale.shape[0], time_steps, -1))\n",
    "\n",
    "# Now define the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, reX_train_wholesaleturn_sequences=True, activation=\"tanh\", input_shape=(X_train_wholesale.shape[1], X_train_wholesale.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))  # If predicting only one value (Wholesale or Retail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Define the LSTM model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m----> 8\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(\u001b[38;5;241m50\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X_lstm_wholesale\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[43mX_train_wholesale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m)))\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.2\u001b[39m))\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(\u001b[38;5;241m50\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True,  activation=\"tanh\", input_shape=(X_lstm_wholesale.shape[1], X_train_wholesale.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))  # 2 output neurons for Wholesale and Retail prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "620/620 [==============================] - 89s 31ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/6\n",
      "620/620 [==============================] - 18s 29ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/6\n",
      "620/620 [==============================] - 16s 26ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/6\n",
      "620/620 [==============================] - 14s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/6\n",
      "620/620 [==============================] - 14s 22ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/6\n",
      "620/620 [==============================] - 17s 27ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_wholesale, y_train_wholesale, epochs=6, batch_size= 20, validation_data=(X_test_wholesale,y_test_wholesale), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 1s 12ms/step - loss: nan\n",
      "Test Loss: nan\n",
      "97/97 [==============================] - 4s 11ms/step\n",
      "Predicted Prices: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Actual Prices: [0.11665617 0.07498575 0.04198542 0.08164582 0.0499805 ]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss = model.evaluate(X_test_wholesale, y_test_wholesale)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_wholesale)\n",
    "\n",
    "# Compare predictions with actual values\n",
    "print(\"Predicted Prices:\", y_pred[:5])\n",
    "print(\"Actual Prices:\", y_test_wholesale[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_predictions(test, predicted):\n",
    "#     plt.plot(test, color=\"gray\", label=\"Real\")\n",
    "#     plt.plot(predicted, color=\"red\", label=\"Predicted\")\n",
    "#     plt.title(\"MasterCard Stock Price Prediction\")\n",
    "#     plt.xlabel(\"Time\")\n",
    "#     plt.ylabel(\"MasterCard Stock Price\")\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# def return_rmse(test, predicted):\n",
    "#     rmse = np.sqrt(mean_squared_error(test, predicted))\n",
    "#     print(\"The root mean squared error is {:.2f}.\".format(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.02400000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.59323782e-01, 8.01830832e-03, 1.37214325e-02],\n",
       "        [2.02400000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.57201022e-01, 8.01830832e-03, 1.39832934e-02],\n",
       "        [2.02400000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.55073181e-01, 8.01830832e-03, 1.56933572e-02],\n",
       "        ...,\n",
       "        [2.02400000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.40188396e-01, 1.01063028e-02, 6.59764698e-03],\n",
       "        [2.02100000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         2.49892846e-01, 6.71343552e-03, 1.67441089e-02],\n",
       "        [2.02100000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.42734677e-01, 6.71343552e-03, 1.67441089e-02]],\n",
       "\n",
       "       [[2.02200000e+03, 1.00000000e+00, 4.44089210e-16, ...,\n",
       "         1.24874979e-01, 1.00701535e-02, 2.09301356e-02],\n",
       "        [2.02300000e+03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         1.74786881e-01, 1.12386614e-01, 7.31514767e-02],\n",
       "        [2.02100000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.15945138e-01, 3.35671776e-03, 0.00000000e+00],\n",
       "        ...,\n",
       "        [2.02100000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.11480214e-01, 1.01598194e-02, 4.05310327e-03],\n",
       "        [2.02100000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.10842362e-01, 9.39392578e-03, 3.95542383e-03],\n",
       "        [2.02100000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.09566674e-01, 8.10442679e-03, 3.61079141e-03]],\n",
       "\n",
       "       [[2.02300000e+03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.97608852e-01, 6.09490611e-02, 6.76164404e-02],\n",
       "        [2.02300000e+03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.25883299e-01, 5.73690459e-02, 6.85299635e-02],\n",
       "        [2.02300000e+03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.47320020e-01, 5.83609231e-02, 6.92778081e-02],\n",
       "        ...,\n",
       "        [2.02300000e+03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.52254391e-01, 9.66304988e-02, 8.69429186e-02],\n",
       "        [2.02300000e+03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.21530640e-01, 1.05931342e-01, 9.53093320e-02],\n",
       "        [2.02300000e+03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.90638447e-01, 1.05812579e-01, 9.51992869e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[2.02100000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.55491605e-01, 1.19146490e-02, 7.22158281e-03],\n",
       "        [2.02100000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.58042982e-01, 7.17696454e-03, 5.59381396e-03],\n",
       "        [2.02100000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.60594374e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [2.02100000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.60594374e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.02100000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.60594374e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.02100000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         1.60594374e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[2.02300000e+03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.14173451e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.02300000e+03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.14173451e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.02300000e+03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.14173451e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [2.02400000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         2.14173451e-01, 1.79585759e-02, 0.00000000e+00],\n",
       "        [2.02400000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         2.14173451e-01, 1.79585759e-02, 0.00000000e+00],\n",
       "        [2.02400000e+03, 5.00000000e-01, 1.00000000e+00, ...,\n",
       "         2.14173451e-01, 1.79585759e-02, 0.00000000e+00]],\n",
       "\n",
       "       [[2.02200000e+03, 1.00000000e+00, 4.44089210e-16, ...,\n",
       "         2.29481757e-01, 4.11647260e-02, 2.88863312e-02],\n",
       "        [2.02200000e+03, 1.00000000e+00, 4.44089210e-16, ...,\n",
       "         2.39687309e-01, 3.59333158e-02, 2.23752558e-02],\n",
       "        [2.02200000e+03, 1.00000000e+00, 4.44089210e-16, ...,\n",
       "         2.49892846e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [2.02200000e+03, 1.00000000e+00, 4.44089210e-16, ...,\n",
       "         2.49892846e-01, 1.27100600e-02, 0.00000000e+00],\n",
       "        [2.02200000e+03, 1.00000000e+00, 4.44089210e-16, ...,\n",
       "         2.49892846e-01, 1.27100600e-02, 0.00000000e+00],\n",
       "        [2.02300000e+03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.49892846e-01, 1.27100600e-02, 0.00000000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_wholesale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
